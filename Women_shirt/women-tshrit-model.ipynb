{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84705,"databundleVersionId":9755748,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport gc\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndf = pd.read_parquet('/kaggle/input/visual-taxonomy/category_attributes.parquet')\nprint(df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-02T14:47:53.685322Z","iopub.execute_input":"2024-11-02T14:47:53.685712Z","iopub.status.idle":"2024-11-02T14:47:55.085116Z","shell.execute_reply.started":"2024-11-02T14:47:53.685654Z","shell.execute_reply":"2024-11-02T14:47:55.083985Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = \"/kaggle/input/visual-taxonomy/train.csv\"\ntrain_df = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:00.214926Z","iopub.execute_input":"2024-11-02T14:48:00.215400Z","iopub.status.idle":"2024-11-02T14:48:00.433108Z","shell.execute_reply.started":"2024-11-02T14:48:00.215354Z","shell.execute_reply":"2024-11-02T14:48:00.432332Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp = train_df.groupby('Category').apply(len)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:07.579222Z","iopub.execute_input":"2024-11-02T14:48:07.579950Z","iopub.status.idle":"2024-11-02T14:48:07.611847Z","shell.execute_reply.started":"2024-11-02T14:48:07.579903Z","shell.execute_reply":"2024-11-02T14:48:07.610932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(temp)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T16:42:24.059118Z","iopub.execute_input":"2024-10-30T16:42:24.059518Z","iopub.status.idle":"2024-10-30T16:42:24.066261Z","shell.execute_reply.started":"2024-10-30T16:42:24.059482Z","shell.execute_reply":"2024-10-30T16:42:24.065016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l = df['Attribute_list'][3]","metadata":{"execution":{"iopub.status.busy":"2024-11-02T11:28:20.672844Z","iopub.execute_input":"2024-11-02T11:28:20.673340Z","iopub.status.idle":"2024-11-02T11:28:20.679593Z","shell.execute_reply.started":"2024-11-02T11:28:20.673287Z","shell.execute_reply":"2024-11-02T11:28:20.678035Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for item in l :\n    print(item)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T11:28:22.834080Z","iopub.execute_input":"2024-11-02T11:28:22.834650Z","iopub.status.idle":"2024-11-02T11:28:22.841862Z","shell.execute_reply.started":"2024-11-02T11:28:22.834595Z","shell.execute_reply":"2024-11-02T11:28:22.840463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_women = train_df.loc[train_df['Category'] == 'Women Tshirts']\ndf_women.reset_index(drop=True, inplace=True)\n# for i in range(1,9) :\n#     temp = df_women.groupby(f'attr_{i}').apply(len)\n#     print(temp) \n#     print('--------------------------------------------')\n#     print('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:16.668942Z","iopub.execute_input":"2024-11-02T14:48:16.669339Z","iopub.status.idle":"2024-11-02T14:48:16.688826Z","shell.execute_reply.started":"2024-11-02T14:48:16.669301Z","shell.execute_reply":"2024-11-02T14:48:16.688033Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.utils import normalize, to_categorical\npd.options.mode.chained_assignment = None","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:19.521705Z","iopub.execute_input":"2024-11-02T14:48:19.522077Z","iopub.status.idle":"2024-11-02T14:48:32.808935Z","shell.execute_reply.started":"2024-11-02T14:48:19.522029Z","shell.execute_reply":"2024-11-02T14:48:32.807958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\nfrom sklearn.preprocessing import LabelBinarizer\nimport numpy as np\nfrom tqdm import tqdm\nfrom keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:32.811008Z","iopub.execute_input":"2024-11-02T14:48:32.811792Z","iopub.status.idle":"2024-11-02T14:48:33.429632Z","shell.execute_reply.started":"2024-11-02T14:48:32.811744Z","shell.execute_reply":"2024-11-02T14:48:33.428861Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:33.430732Z","iopub.execute_input":"2024-11-02T14:48:33.431240Z","iopub.status.idle":"2024-11-02T14:48:33.535187Z","shell.execute_reply.started":"2024-11-02T14:48:33.431204Z","shell.execute_reply":"2024-11-02T14:48:33.534326Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf_women['attr_5'] = df_women[\"attr_5\"].astype('category').cat.codes\n\n\ny_print_or_pattern_type = to_categorical(np.array(df_women['attr_5']))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:33.536786Z","iopub.execute_input":"2024-11-02T14:48:33.537085Z","iopub.status.idle":"2024-11-02T14:48:33.546480Z","shell.execute_reply.started":"2024-11-02T14:48:33.537041Z","shell.execute_reply":"2024-11-02T14:48:33.545543Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_directory = \"/kaggle/input/visual-taxonomy/train_images/\"\nSIZE=200\nX_dataset = []  \nfor i in tqdm(range(df_women.shape[0])):\n    prep = str(df_women['id'][i])\n    prep = '0'*(6-len(prep)) + prep\n    img = image.load_img(image_directory +prep+'.jpg', target_size=(SIZE,SIZE,3))\n    img = image.img_to_array(img)\n    img = img/255.\n    X_dataset.append(img)\nX = np.array(X_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:48:38.017763Z","iopub.execute_input":"2024-11-02T14:48:38.018152Z","iopub.status.idle":"2024-11-02T14:51:09.967312Z","shell.execute_reply.started":"2024-11-02T14:48:38.018114Z","shell.execute_reply":"2024-11-02T14:51:09.966287Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nNUM_CLASSES_PP = len(df_women['attr_5'].unique())-1\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:51:13.272527Z","iopub.execute_input":"2024-11-02T14:51:13.273162Z","iopub.status.idle":"2024-11-02T14:51:13.279448Z","shell.execute_reply.started":"2024-11-02T14:51:13.273123Z","shell.execute_reply":"2024-11-02T14:51:13.278491Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = (200, 200, 3)\n\n\n# Load the base model with pre-trained weights\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=IMAGE_SIZE)\n\n# Freeze the base model\nbase_model.trainable = True","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:51:15.546869Z","iopub.execute_input":"2024-11-02T14:51:15.547546Z","iopub.status.idle":"2024-11-02T14:51:18.337805Z","shell.execute_reply.started":"2024-11-02T14:51:15.547507Z","shell.execute_reply":"2024-11-02T14:51:18.336791Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(base_model.layers))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T12:11:50.404806Z","iopub.execute_input":"2024-11-02T12:11:50.405412Z","iopub.status.idle":"2024-11-02T12:11:50.413200Z","shell.execute_reply.started":"2024-11-02T12:11:50.405359Z","shell.execute_reply":"2024-11-02T12:11:50.411853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tune from this layer onwards\nfine_tune_at = 130\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[0:]:\n  layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:51:29.559468Z","iopub.execute_input":"2024-11-02T14:51:29.559851Z","iopub.status.idle":"2024-11-02T14:51:29.568893Z","shell.execute_reply.started":"2024-11-02T14:51:29.559814Z","shell.execute_reply":"2024-11-02T14:51:29.568012Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras ","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:51:31.983396Z","iopub.execute_input":"2024-11-02T14:51:31.984092Z","iopub.status.idle":"2024-11-02T14:51:31.988061Z","shell.execute_reply.started":"2024-11-02T14:51:31.984034Z","shell.execute_reply":"2024-11-02T14:51:31.987026Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Split into training and validation sets (80% train, 20% validation)\nX_train, X_val, y_train, y_val = train_test_split(\n    X,\n    y_print_or_pattern_type,\n    test_size=0.2,\n    random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:52:00.906783Z","iopub.execute_input":"2024-11-02T14:52:00.907182Z","iopub.status.idle":"2024-11-02T14:52:06.139430Z","shell.execute_reply.started":"2024-11-02T14:52:00.907144Z","shell.execute_reply":"2024-11-02T14:52:06.138576Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del X\ndel train_df \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:52:24.352663Z","iopub.execute_input":"2024-11-02T14:52:24.353020Z","iopub.status.idle":"2024-11-02T14:52:24.569052Z","shell.execute_reply.started":"2024-11-02T14:52:24.352987Z","shell.execute_reply":"2024-11-02T14:52:24.568084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_CLASSES_PP = len(df_women['attr_5'].unique())-1","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:52:29.059871Z","iopub.execute_input":"2024-11-02T14:52:29.060857Z","iopub.status.idle":"2024-11-02T14:52:29.065784Z","shell.execute_reply.started":"2024-11-02T14:52:29.060804Z","shell.execute_reply":"2024-11-02T14:52:29.064952Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the combined labels back into their respective arrays\ntrain_color_labels = y_train[:, :NUM_CLASSES_COLOR]\ntrain_fs_labels = y_train[:, NUM_CLASSES_COLOR:NUM_CLASSES_COLOR + NUM_CLASSES_FS]\ntrain_length_labels = y_train[:, NUM_CLASSES_COLOR + NUM_CLASSES_FS:NUM_CLASSES_COLOR + NUM_CLASSES_FS + NUM_CLASSES_LENGTH]\ntrain_pattern_labels = y_train[:, NUM_CLASSES_COLOR + NUM_CLASSES_FS + NUM_CLASSES_LENGTH:NUM_CLASSES_COLOR + NUM_CLASSES_FS + NUM_CLASSES_LENGTH + NUM_CLASSES_PATTERN]\ntrain_pp_labels = y_train[:,  -NUM_CLASSES_SURFACE-NUM_CLASSES_SS-NUM_CLASSES_SL-NUM_CLASSES_PP:-NUM_CLASSES_SURFACE-NUM_CLASSES_SS-NUM_CLASSES_SL]\ntrain_sl_labels = y_train[:, -NUM_CLASSES_SURFACE-NUM_CLASSES_SS-NUM_CLASSES_SL:-NUM_CLASSES_SURFACE-NUM_CLASSES_SS]\ntrain_ss_labels = y_train[:, -NUM_CLASSES_SURFACE-NUM_CLASSES_SS:-NUM_CLASSES_SURFACE]\ntrain_surface_labels = y_train[:, -NUM_CLASSES_SURFACE:]\n\nval_color_labels = y_val[:, :NUM_CLASSES_COLOR]\nval_fs_labels = y_val[:, NUM_CLASSES_COLOR:NUM_CLASSES_COLOR + NUM_CLASSES_FS]\nval_length_labels = y_val[:, NUM_CLASSES_COLOR + NUM_CLASSES_FS:NUM_CLASSES_COLOR + NUM_CLASSES_FS + NUM_CLASSES_LENGTH]\nval_pattern_labels = y_val[:, NUM_CLASSES_COLOR + NUM_CLASSES_FS + NUM_CLASSES_LENGTH:NUM_CLASSES_COLOR + NUM_CLASSES_FS + NUM_CLASSES_LENGTH + NUM_CLASSES_PATTERN]\nval_pp_labels = y_val[:,  -NUM_CLASSES_SURFACE-NUM_CLASSES_SS-NUM_CLASSES_SL-NUM_CLASSES_PP:-NUM_CLASSES_SURFACE-NUM_CLASSES_SS-NUM_CLASSES_SL]\nval_sl_labels = y_val[:, -NUM_CLASSES_SURFACE-NUM_CLASSES_SS-NUM_CLASSES_SL:-NUM_CLASSES_SURFACE-NUM_CLASSES_SS]\nval_ss_labels = y_val[:, -NUM_CLASSES_SURFACE-NUM_CLASSES_SS:-NUM_CLASSES_SURFACE]\nval_surface_labels = y_val[:, -NUM_CLASSES_SURFACE:]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:44:26.738563Z","iopub.execute_input":"2024-10-31T06:44:26.739488Z","iopub.status.idle":"2024-10-31T06:44:26.756982Z","shell.execute_reply.started":"2024-10-31T06:44:26.739434Z","shell.execute_reply":"2024-10-31T06:44:26.755753Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# resnet_model = Sequential()\n\n# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n#                    input_shape=(180,180,3),\n#                    pooling='avg',classes=5,\n#                    weights='imagenet')\n# for layer in pretrained_model.layers:\n#         layer.trainable=False\n\n# resnet_model.add(pretrained_model)\n# resnet_model.add(Flatten())\n# resnet_model.add(Dense(512, activation='relu'))\n# resnet_model.add(Dense(5, activation='softmax'))\n\n\n\n# Create a model with five output heads for each attribute\ninputs = layers.Input(shape=IMAGE_SIZE)\nx = base_model(inputs, training=True)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(512, activation='relu')(x)\n# Define output layers for each attribute\noutput_pp = layers.Dense(NUM_CLASSES_PP, activation='softmax', name='pp')(x)\n\n# Define the model\nmodel = models.Model(inputs=inputs, outputs=[output_pp])\n\n# Compile the model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=5*1e-4),\n    loss={\n        'pp': 'categorical_crossentropy',\n    },\n    metrics=['accuracy']\n)\n\n# Summary of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:53:37.714424Z","iopub.execute_input":"2024-11-02T14:53:37.715105Z","iopub.status.idle":"2024-11-02T14:53:37.782555Z","shell.execute_reply.started":"2024-11-02T14:53:37.715054Z","shell.execute_reply":"2024-11-02T14:53:37.781655Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:53:50.140511Z","iopub.execute_input":"2024-11-02T14:53:50.141196Z","iopub.status.idle":"2024-11-02T14:53:50.149681Z","shell.execute_reply.started":"2024-11-02T14:53:50.141152Z","shell.execute_reply":"2024-11-02T14:53:50.148858Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_datagen = ImageDataGenerator(rotation_range=45,\n    width_shift_range=0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:53:54.307629Z","iopub.execute_input":"2024-11-02T14:53:54.308013Z","iopub.status.idle":"2024-11-02T14:53:54.312405Z","shell.execute_reply.started":"2024-11-02T14:53:54.307976Z","shell.execute_reply":"2024-11-02T14:53:54.311567Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiLabelDataGenerator(Sequence):\n    def __init__(self, images, labels, batch_size, datagen):\n        self.images = images\n        self.labels = labels\n        self.batch_size = batch_size\n        self.datagen = datagen\n        self.indices = np.arange(len(images))\n\n    def __len__(self):\n        return int(np.ceil(len(self.images) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_images = self.images[batch_indices]\n        batch_labels = {key: label[batch_indices] for key, label in self.labels.items()}\n        \n        # Apply data augmentation\n        batch_images = np.array([self.datagen.random_transform(img) for img in batch_images])\n\n        return batch_images, batch_labels","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:53:56.341739Z","iopub.execute_input":"2024-11-02T14:53:56.342562Z","iopub.status.idle":"2024-11-02T14:53:56.349983Z","shell.execute_reply.started":"2024-11-02T14:53:56.342518Z","shell.execute_reply":"2024-11-02T14:53:56.349123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_labels = {\n    'pp': y_train\n}\nbatch_size = 32\ntrain_generator = MultiLabelDataGenerator(X_train, train_labels, batch_size, train_datagen)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:53:58.443920Z","iopub.execute_input":"2024-11-02T14:53:58.444951Z","iopub.status.idle":"2024-11-02T14:53:58.452776Z","shell.execute_reply.started":"2024-11-02T14:53:58.444885Z","shell.execute_reply":"2024-11-02T14:53:58.451716Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_filepath = '/kaggle/working/checkpoint.model.keras'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_pp_accuracy',\n    mode='max',\n    save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:54:03.492084Z","iopub.execute_input":"2024-11-02T14:54:03.492872Z","iopub.status.idle":"2024-11-02T14:54:03.497412Z","shell.execute_reply.started":"2024-11-02T14:54:03.492829Z","shell.execute_reply":"2024-11-02T14:54:03.496399Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.optimizers import Adam\n\n# Custom callback to progressively unfreeze layers\nclass GradualUnfreeze(Callback):\n    def __init__(self,total_epochs, layers_to_unfreeze_per_epoch):\n        super().__init__()\n        self.total_epochs = total_epochs\n        self.layers_to_unfreeze_per_epoch = layers_to_unfreeze_per_epoch\n\n    def on_epoch_begin(self, epoch, logs=None):\n        # Calculate number of layers to unfreeze based on epoch\n        num_layers_to_unfreeze = min(25,(epoch) * self.layers_to_unfreeze_per_epoch)\n        if num_layers_to_unfreeze :\n            for layer in self.model.layers[-num_layers_to_unfreeze:]:\n                layer.trainable = True\n        lr = 5e-4 * (max(0.02, 1-(epoch/50)))\n        self.model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n        self.model.make_train_function()\n        print(f\"Epoch {epoch+1}: Unfroze top {num_layers_to_unfreeze} layers. Learning Rate is {lr}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T14:54:18.551658Z","iopub.execute_input":"2024-11-02T14:54:18.552524Z","iopub.status.idle":"2024-11-02T14:54:18.565351Z","shell.execute_reply.started":"2024-11-02T14:54:18.552483Z","shell.execute_reply":"2024-11-02T14:54:18.564419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\ntrain_generator,  # Image data\nvalidation_data=(X_val, {\n'pp': y_val, \n}),\nepochs=80,\ncallbacks=[model_checkpoint_callback, GradualUnfreeze(80,1)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T14:54:33.668506Z","iopub.execute_input":"2024-11-02T14:54:33.669353Z","iopub.status.idle":"2024-11-02T15:38:23.669090Z","shell.execute_reply.started":"2024-11-02T14:54:33.669312Z","shell.execute_reply":"2024-11-02T15:38:23.667626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming 'history' is the output from model.fit()\n# Example: history = model.fit(...)\n\n# Plotting the accuracy\nplt.figure(figsize=(12, 6))\n\n# Plot training accuracy\n\nplt.plot(history.history['pp_accuracy'], label='Pattern Train Accuracy', color='green')\n\n# Plot validation accuracy\n\nplt.plot(history.history['val_pp_accuracy'], label='Pattern Validation Accuracy', linestyle='dashed', color='green')\n\n# Adding labels and title\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:39:14.922267Z","iopub.execute_input":"2024-10-31T08:39:14.922678Z","iopub.status.idle":"2024-10-31T08:39:15.243159Z","shell.execute_reply.started":"2024-10-31T08:39:14.922638Z","shell.execute_reply":"2024-10-31T08:39:15.242147Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"color\nfit_shape\nlength\npattern\nprint_or_pattern_type\nsleeve_length\nsleeve_styling\nsurface_stylin","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T18:52:23.367373Z","iopub.execute_input":"2024-10-30T18:52:23.367766Z","iopub.status.idle":"2024-10-30T18:52:23.388918Z","shell.execute_reply.started":"2024-10-30T18:52:23.367726Z","shell.execute_reply":"2024-10-30T18:52:23.387935Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:39:35.053601Z","iopub.execute_input":"2024-10-31T08:39:35.053998Z","iopub.status.idle":"2024-10-31T08:39:35.058773Z","shell.execute_reply.started":"2024-10-31T08:39:35.053959Z","shell.execute_reply":"2024-10-31T08:39:35.057717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:39:37.333273Z","iopub.execute_input":"2024-10-31T08:39:37.333679Z","iopub.status.idle":"2024-10-31T08:39:37.338317Z","shell.execute_reply.started":"2024-10-31T08:39:37.333640Z","shell.execute_reply":"2024-10-31T08:39:37.336914Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FileLink(r'/kaggle/working/checkpoint.model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:39:39.898696Z","iopub.execute_input":"2024-10-31T08:39:39.899315Z","iopub.status.idle":"2024-10-31T08:39:39.905214Z","shell.execute_reply.started":"2024-10-31T08:39:39.899278Z","shell.execute_reply":"2024-10-31T08:39:39.904319Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.optimizers import Adam\n\n# Custom callback to progressively unfreeze layers\nclass GradualUnfreeze(Callback):\n    def __init__(self, model, total_epochs, layers_to_unfreeze_per_epoch):\n        super().__init__()\n        self.model = model\n        self.total_epochs = total_epochs\n        self.layers_to_unfreeze_per_epoch = layers_to_unfreeze_per_epoch\n\n    def on_epoch_begin(self, epoch, logs=None):\n        # Calculate number of layers to unfreeze based on epoch\n        num_layers_to_unfreeze = (epoch + 1) * self.layers_to_unfreeze_per_epoch\n        for layer in self.model.layers[-num_layers_to_unfreeze:]:\n            layer.trainable = True\n        self.model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n        print(f\"Epoch {epoch+1}: Unfroze top {num_layers_to_unfreeze} layers.\")\n\n# Load or define your model\nbase_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(200, 200, 3))\nx = GlobalAveragePooling2D()(base_model.output)\noutput = Dense(num_classes, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Freeze all layers initially\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile model with frozen base layers\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Define number of epochs and layers to unfreeze per epoch\ntotal_epochs = 20\nlayers_to_unfreeze_per_epoch = 2  # Adjust based on model depth and desired unfreeze speed\n\n# Start training with the callback\nhistory = model.fit(\n    train_data,\n    epochs=total_epochs,\n    validation_data=validation_data,\n    callbacks=[GradualUnfreeze(model, total_epochs, layers_to_unfreeze_per_epoch)]\n)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# resnet_model = Sequential()\n\n# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n#                    input_shape=(180,180,3),\n#                    pooling='avg',classes=5,\n#                    weights='imagenet')\n# for layer in pretrained_model.layers:\n#         layer.trainable=False\n\n# resnet_model.add(pretrained_model)\n# resnet_model.add(Flatten())\n# resnet_model.add(Dense(512, activation='relu'))\n# resnet_model.add(Dense(5, activation='softmax'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# class GradualUnfreeze(Callback):\n#     def __init__(self,total_epochs, layers_to_unfreeze_per_epoch):\n#         super().__init__()\n#         self.total_epochs = total_epochs\n#         self.layers_to_unfreeze_per_epoch = layers_to_unfreeze_per_epoch\n\n#     def on_epoch_begin(self, epoch, logs=None):\n#         # Calculate number of layers to unfreeze based on epoch\n#         num_layers_to_unfreeze = min(25,(epoch + 1) * self.layers_to_unfreeze_per_epoch)\n#         for layer in self.model.layers[-num_layers_to_unfreeze:]:\n#             layer.trainable = True\n#         lr = 5e-4 * (max(0.02, 1-(epoch/50)))\n#         self.model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n#         print(f\"Epoch {epoch+1}: Unfroze top {num_layers_to_unfreeze} layers. Learning Rate is {lr}\")\n\n\n\n\n\n\nclass GradualUnfreezeCallback(Callback):\n    \"\"\"\n    Callback to gradually unfreeze ResNet layers during training.\n    Unfreezes layers from top to bottom (deepest to shallowest).\n    \"\"\"\n    def __init__(self, base_model, initial_trainable_layers=0, layers_to_unfreeze_per_epoch=10):\n        super().__init__()\n        self.base_model = base_model\n        self.layers_to_unfreeze_per_epoch = layers_to_unfreeze_per_epoch\n        self.initial_trainable_layers = initial_trainable_layers\n        self.learning_rates = {\n            0: 1e-3,    # Initial learning rate for just the top layers\n            10: 5e-4,   # Reduced learning rate when unfreezing begins\n            30: 1e-4,   # Further reduced for fine-tuning deeper layers\n            50: 5e-5    # Final fine-tuning\n        }\n\n    def on_epoch_begin(self, epoch, logs=None):\n        # Calculate how many layers should be trainable\n        trainable_layers = min(\n            self.initial_trainable_layers + (epoch * self.layers_to_unfreeze_per_epoch),\n            len(self.base_model.layers)\n        )\n        \n        # Freeze/unfreeze layers accordingly\n        for i, layer in enumerate(self.base_model.layers):\n            layer.trainable = i >= (len(self.base_model.layers) - trainable_layers)\n        \n        # Adjust learning rate based on epoch\n        for epoch_threshold, lr in self.learning_rates.items():\n            if epoch >= epoch_threshold:\n                current_lr = lr\n                \n        # Recompile the model with the new trainable layers and learning rate\n        self.model.compile(\n            optimizer=Adam(learning_rate=current_lr),\n            loss='categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        # Print status\n        trainable_params = np.sum([tf.keras.backend.count_params(w) for w in self.model.trainable_weights])\n        print(f\"\\nEpoch {epoch + 1}:\")\n        print(f\"Trainable layers: {trainable_layers}\")\n        print(f\"Trainable parameters: {trainable_params:,}\")\n        print(f\"Learning rate: {current_lr}\")\n\ndef create_fine_tuning_model(num_classes, input_shape=(224, 224, 3)):\n    \"\"\"\n    Creates a ResNet50 model for fine-tuning with custom top layers.\n    \"\"\"\n    # Load pre-trained ResNet without top layers\n    base_model = ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    \n    # Add custom top layers\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n    \n    model = Model(inputs=base_model.input, outputs=outputs)\n    \n    # Initially freeze all ResNet layers\n    for layer in base_model.layers:\n        layer.trainable = False\n        \n    return model, base_model\n\ndef train_with_gradual_unfreeze(\n    train_data,\n    validation_data,\n    num_classes,\n    input_shape=(224, 224, 3),\n    epochs=100,\n    batch_size=32,\n    initial_trainable_layers=0,\n    layers_to_unfreeze_per_epoch=10\n):\n    \"\"\"\n    Trains the model with gradual unfreezing of layers.\n    \"\"\"\n    # Create model\n    model, base_model = create_fine_tuning_model(num_classes, input_shape)\n    \n    # Create callbacks\n    callbacks = [\n        GradualUnfreezeCallback(\n            base_model,\n            initial_trainable_layers=initial_trainable_layers,\n            layers_to_unfreeze_per_epoch=layers_to_unfreeze_per_epoch\n        ),\n        ModelCheckpoint(\n            'best_model.h5',\n            monitor='val_accuracy',\n            mode='max',\n            save_best_only=True,\n            verbose=1\n        ),\n        EarlyStopping(\n            monitor='val_accuracy',\n            mode='max',\n            patience=10,\n            restore_best_weights=True,\n            verbose=1\n        )\n    ]\n    \n    # Initial compilation\n    model.compile(\n        optimizer=Adam(learning_rate=1e-3),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    # Train the model\n    history = model.fit(\n        train_data,\n        validation_data=validation_data,\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    return model, history\n\n\ntrain_generator = train_datagen.flow(\n    X_train,\n    y_train,\n    batch_size = 32)\n\n# Example usage:\n\"\"\"\n# Assuming you have your data prepared as tf.data.Dataset objects:\ntrain_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalidation_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n\n# Train the model\nmodel, history = train_with_gradual_unfreeze(\n    train_data=train_data,\n    validation_data=validation_data,\n    num_classes=10,\n    epochs=100,\n    batch_size=32,\n    initial_trainable_layers=0,\n    layers_to_unfreeze_per_epoch=10\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}