{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84705,"databundleVersionId":9755748,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndf = pd.read_parquet('/kaggle/input/visual-taxonomy/category_attributes.parquet')\nprint(df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T17:49:32.381987Z","iopub.execute_input":"2024-11-01T17:49:32.382425Z","iopub.status.idle":"2024-11-01T17:49:32.398501Z","shell.execute_reply.started":"2024-11-01T17:49:32.382382Z","shell.execute_reply":"2024-11-01T17:49:32.397211Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = \"/kaggle/input/visual-taxonomy/train.csv\"\ntrain_df = pd.read_csv(train_path)\n\ndf_men = train_df.loc[train_df['Category'] == 'Men Tshirts']\ndf_men.reset_index(drop=True, inplace=True)\ndf_men","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:32.881366Z","iopub.execute_input":"2024-11-01T17:49:32.881968Z","iopub.status.idle":"2024-11-01T17:49:33.062541Z","shell.execute_reply.started":"2024-11-01T17:49:32.881927Z","shell.execute_reply":"2024-11-01T17:49:33.061469Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp = train_df.groupby('Category').apply(len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.064256Z","iopub.execute_input":"2024-11-01T17:49:33.064582Z","iopub.status.idle":"2024-11-01T17:49:33.089417Z","shell.execute_reply.started":"2024-11-01T17:49:33.064547Z","shell.execute_reply":"2024-11-01T17:49:33.088407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.090661Z","iopub.execute_input":"2024-11-01T17:49:33.091019Z","iopub.status.idle":"2024-11-01T17:49:33.096433Z","shell.execute_reply.started":"2024-11-01T17:49:33.090979Z","shell.execute_reply":"2024-11-01T17:49:33.095526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l = df['Attribute_list'][0]\nl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.099336Z","iopub.execute_input":"2024-11-01T17:49:33.099670Z","iopub.status.idle":"2024-11-01T17:49:33.105923Z","shell.execute_reply.started":"2024-11-01T17:49:33.099619Z","shell.execute_reply":"2024-11-01T17:49:33.105066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for item in l :\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.107070Z","iopub.execute_input":"2024-11-01T17:49:33.107540Z","iopub.status.idle":"2024-11-01T17:49:33.113819Z","shell.execute_reply.started":"2024-11-01T17:49:33.107498Z","shell.execute_reply":"2024-11-01T17:49:33.112896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.utils import normalize, to_categorical\npd.options.mode.chained_assignment = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.114709Z","iopub.execute_input":"2024-11-01T17:49:33.115020Z","iopub.status.idle":"2024-11-01T17:49:33.120927Z","shell.execute_reply.started":"2024-11-01T17:49:33.114989Z","shell.execute_reply":"2024-11-01T17:49:33.120135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom sklearn.preprocessing import LabelBinarizer\nimport numpy as np\nfrom tqdm import tqdm\nfrom keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:33.121857Z","iopub.execute_input":"2024-11-01T17:49:33.122136Z","iopub.status.idle":"2024-11-01T17:49:33.128756Z","shell.execute_reply.started":"2024-11-01T17:49:33.122081Z","shell.execute_reply":"2024-11-01T17:49:33.127900Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.130028Z","iopub.execute_input":"2024-11-01T17:49:33.130576Z","iopub.status.idle":"2024-11-01T17:49:33.136013Z","shell.execute_reply.started":"2024-11-01T17:49:33.130534Z","shell.execute_reply":"2024-11-01T17:49:33.135281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Initialize a dictionary to store mappings for each attribute\nmappings = {}\n\n# Iterate through each attribute column to create and save mappings\nfor attr in df_men.columns[3:8]:  # Adjust column range if necessary\n    # Convert column to categorical and get the categories\n    c = df_men[attr].astype('category')\n    df_men[attr] = c.cat.codes  # Apply cat.codes to the DataFrame\n    \n    # Store the mapping of integer codes to original categories\n    mappings[attr] = dict(enumerate(c.cat.categories))\n\n# Display the mappings for verification\nprint(\"Mappings:\")\nfor key, value in mappings.items():\n    print(f\"{key}: {value}\")\n\n# Save mappings to /kaggle/working/ for download\nwith open(\"/kaggle/working/attribute_mappings.json\", \"w\") as f:\n    json.dump(mappings, f, indent=4)\n\nprint(\"\\nMappings saved to /kaggle/working/attribute_mappings.json\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:33.138032Z","iopub.execute_input":"2024-11-01T17:49:33.138366Z","iopub.status.idle":"2024-11-01T17:49:33.156241Z","shell.execute_reply.started":"2024-11-01T17:49:33.138335Z","shell.execute_reply":"2024-11-01T17:49:33.155287Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# df_men[\"attr_1\"] = df_men[\"attr_1\"].astype('category').cat.codes\n# df_men[\"attr_2\"] = df_men[\"attr_2\"].astype('category').cat.codes\n# df_men[\"attr_3\"] = df_men[\"attr_3\"].astype('category').cat.codes\n# df_men[\"attr_4\"] = df_men[\"attr_4\"].astype('category').cat.codes\n# df_men[\"attr_5\"] = df_men[\"attr_5\"].astype('category').cat.codes\ny_color = np.array(df_men[\"attr_1\"])\ny_neck = np.array(df_men[\"attr_2\"])\ny_pattern = np.array(df_men[\"attr_3\"])\ny_print = np.array(df_men[\"attr_4\"])\ny_sleeve = np.array(df_men[\"attr_5\"])\ny_color = to_categorical(y_color)\ny_neck = to_categorical(y_neck)\ny_pattern = to_categorical(y_pattern)\ny_print = to_categorical(y_print)\ny_sleeve = to_categorical(y_sleeve)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:33.157991Z","iopub.execute_input":"2024-11-01T17:49:33.158683Z","iopub.status.idle":"2024-11-01T17:49:33.166561Z","shell.execute_reply.started":"2024-11-01T17:49:33.158640Z","shell.execute_reply":"2024-11-01T17:49:33.165627Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_directory = \"/kaggle/input/visual-taxonomy/train_images/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.167970Z","iopub.execute_input":"2024-11-01T17:49:33.168532Z","iopub.status.idle":"2024-11-01T17:49:33.172558Z","shell.execute_reply.started":"2024-11-01T17:49:33.168496Z","shell.execute_reply":"2024-11-01T17:49:33.171611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(df))\nprint(len(y_color))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:49:33.200558Z","iopub.execute_input":"2024-11-01T17:49:33.201187Z","iopub.status.idle":"2024-11-01T17:49:33.205612Z","shell.execute_reply.started":"2024-11-01T17:49:33.201150Z","shell.execute_reply":"2024-11-01T17:49:33.204590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SIZE=200\nX_dataset = []  \nfor i in tqdm(range(df_men.shape[0])):\n    prep = str(df_men['id'][i])\n    prep = '0'*(6-len(prep)) + prep\n    img = image.load_img(image_directory +prep+'.jpg', target_size=(SIZE,SIZE,3))\n    img = image.img_to_array(img)\n    # img = img/255.\n    img = preprocess_input(img)\n    X_dataset.append(img)\nX = np.array(X_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:33.230542Z","iopub.execute_input":"2024-11-01T17:49:33.231187Z","iopub.status.idle":"2024-11-01T17:49:51.646209Z","shell.execute_reply.started":"2024-11-01T17:49:33.231154Z","shell.execute_reply":"2024-11-01T17:49:51.645377Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = (200, 200, 3)\n\n\n# Load the base model with pre-trained weights\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=IMAGE_SIZE)\n\n# Freeze the base model: False\nbase_model.trainable = True","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:51.647888Z","iopub.execute_input":"2024-11-01T17:49:51.648228Z","iopub.status.idle":"2024-11-01T17:49:52.758683Z","shell.execute_reply.started":"2024-11-01T17:49:51.648194Z","shell.execute_reply":"2024-11-01T17:49:52.757890Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:49:52.759727Z","iopub.execute_input":"2024-11-01T17:49:52.760015Z","iopub.status.idle":"2024-11-01T17:49:52.986974Z","shell.execute_reply.started":"2024-11-01T17:49:52.759984Z","shell.execute_reply":"2024-11-01T17:49:52.986163Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(base_model.layers))","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:50:51.971089Z","iopub.execute_input":"2024-11-01T17:50:51.971965Z","iopub.status.idle":"2024-11-01T17:50:51.976685Z","shell.execute_reply.started":"2024-11-01T17:50:51.971923Z","shell.execute_reply":"2024-11-01T17:50:51.975811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tune from this layer onwards\nfine_tune_at = 150\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:50:54.280776Z","iopub.execute_input":"2024-11-01T17:50:54.281634Z","iopub.status.idle":"2024-11-01T17:50:54.287189Z","shell.execute_reply.started":"2024-11-01T17:50:54.281593Z","shell.execute_reply":"2024-11-01T17:50:54.286171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:50:55.961454Z","iopub.execute_input":"2024-11-01T17:50:55.962179Z","iopub.status.idle":"2024-11-01T17:50:55.966321Z","shell.execute_reply.started":"2024-11-01T17:50:55.962133Z","shell.execute_reply":"2024-11-01T17:50:55.965165Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ny_combined = np.hstack((y_color, y_neck, y_pattern, y_print, y_sleeve))\n\n# Split into training and validation sets (80% train, 20% validation)\nX_train, X_val, y_train, y_val = train_test_split(\n    X,\n    y_combined,\n    test_size=0.2,\n    random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:50:56.235804Z","iopub.execute_input":"2024-11-01T17:50:56.236623Z","iopub.status.idle":"2024-11-01T17:50:57.225929Z","shell.execute_reply.started":"2024-11-01T17:50:56.236586Z","shell.execute_reply":"2024-11-01T17:50:57.224996Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:51:02.877438Z","iopub.execute_input":"2024-11-01T17:51:02.877814Z","iopub.status.idle":"2024-11-01T17:51:02.882124Z","shell.execute_reply.started":"2024-11-01T17:51:02.877777Z","shell.execute_reply":"2024-11-01T17:51:02.881155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del X\ndel train_df \ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:51:04.121172Z","iopub.execute_input":"2024-11-01T17:51:04.121613Z","iopub.status.idle":"2024-11-01T17:51:04.359758Z","shell.execute_reply.started":"2024-11-01T17:51:04.121559Z","shell.execute_reply":"2024-11-01T17:51:04.358883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# color_classes = df_men['attr_1'].unique()\n# neck_classes = df_men['attr_2'].unique()\n# pattern_classes = df_men['attr_3'].unique()\n# print_classes = df_men['attr_4'].unique()\n# sleeve_classes = df_men['attr_5'].unique()\n\nNUM_CLASSES_COLOR = len(df_men['attr_1'].unique())-1\nNUM_CLASSES_NECK = len(df_men['attr_2'].unique())-1\nNUM_CLASSES_PATTERN = len(df_men['attr_3'].unique())-1\nNUM_CLASSES_PRINT = len(df_men['attr_4'].unique())-1\nNUM_CLASSES_SLEEVE = len(df_men['attr_5'].unique())-1","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:51:18.551854Z","iopub.execute_input":"2024-11-01T17:51:18.552728Z","iopub.status.idle":"2024-11-01T17:51:18.560871Z","shell.execute_reply.started":"2024-11-01T17:51:18.552684Z","shell.execute_reply":"2024-11-01T17:51:18.559939Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the combined labels back into their respective arrays\ntrain_color_labels = y_train[:, :NUM_CLASSES_COLOR]\ntrain_neck_labels = y_train[:, NUM_CLASSES_COLOR:NUM_CLASSES_COLOR + NUM_CLASSES_NECK]\ntrain_pattern_labels = y_train[:, NUM_CLASSES_COLOR + NUM_CLASSES_NECK:NUM_CLASSES_COLOR + NUM_CLASSES_NECK + NUM_CLASSES_PATTERN]\ntrain_print_labels = y_train[:, NUM_CLASSES_COLOR + NUM_CLASSES_NECK + NUM_CLASSES_PATTERN:NUM_CLASSES_COLOR + NUM_CLASSES_NECK + NUM_CLASSES_PATTERN + NUM_CLASSES_PRINT]\ntrain_sleeve_labels = y_train[:, -NUM_CLASSES_SLEEVE:]\n\nval_color_labels = y_val[:, :NUM_CLASSES_COLOR]\nval_neck_labels = y_val[:, NUM_CLASSES_COLOR:NUM_CLASSES_COLOR + NUM_CLASSES_NECK]\nval_pattern_labels = y_val[:, NUM_CLASSES_COLOR + NUM_CLASSES_NECK:NUM_CLASSES_COLOR + NUM_CLASSES_NECK + NUM_CLASSES_PATTERN]\nval_print_labels = y_val[:, NUM_CLASSES_COLOR + NUM_CLASSES_NECK + NUM_CLASSES_PATTERN:NUM_CLASSES_COLOR + NUM_CLASSES_NECK + NUM_CLASSES_PATTERN + NUM_CLASSES_PRINT]\nval_sleeve_labels = y_val[:, -NUM_CLASSES_SLEEVE:]","metadata":{"execution":{"iopub.status.busy":"2024-11-01T17:51:20.721932Z","iopub.execute_input":"2024-11-01T17:51:20.722786Z","iopub.status.idle":"2024-11-01T17:51:20.729672Z","shell.execute_reply.started":"2024-11-01T17:51:20.722741Z","shell.execute_reply":"2024-11-01T17:51:20.728696Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:51:22.105977Z","iopub.execute_input":"2024-11-01T17:51:22.106757Z","iopub.status.idle":"2024-11-01T17:51:22.114202Z","shell.execute_reply.started":"2024-11-01T17:51:22.106716Z","shell.execute_reply":"2024-11-01T17:51:22.113363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    brightness_range=[0.8, 1.2],\n    shear_range=0.15,\n    horizontal_flip=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:57:55.341246Z","iopub.execute_input":"2024-11-01T17:57:55.342153Z","iopub.status.idle":"2024-11-01T17:57:55.346964Z","shell.execute_reply.started":"2024-11-01T17:57:55.342087Z","shell.execute_reply":"2024-11-01T17:57:55.345931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiLabelDataGenerator(Sequence):\n    def __init__(self, images, labels, batch_size, datagen):\n        self.images = images\n        self.labels = labels\n        self.batch_size = batch_size\n        self.datagen = datagen\n        self.indices = np.arange(len(images))\n\n    def __len__(self):\n        return int(np.ceil(len(self.images) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_images = self.images[batch_indices]\n        batch_labels = {key: label[batch_indices] for key, label in self.labels.items()}\n        \n        # Apply data augmentation\n        batch_images = np.array([self.datagen.random_transform(img) for img in batch_images])\n\n        return batch_images, batch_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:57:58.069555Z","iopub.execute_input":"2024-11-01T17:57:58.070324Z","iopub.status.idle":"2024-11-01T17:57:58.077918Z","shell.execute_reply.started":"2024-11-01T17:57:58.070283Z","shell.execute_reply":"2024-11-01T17:57:58.076974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_labels = {\n    'color': train_color_labels,\n    'neck': train_neck_labels,\n    'pattern': train_pattern_labels,\n    'print': train_print_labels,\n    'sleeve': train_sleeve_labels\n}\n\nbatch_size = 32\ntrain_generator = MultiLabelDataGenerator(X_train, train_labels, batch_size, train_datagen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:57:59.187345Z","iopub.execute_input":"2024-11-01T17:57:59.188020Z","iopub.status.idle":"2024-11-01T17:57:59.193249Z","shell.execute_reply.started":"2024-11-01T17:57:59.187977Z","shell.execute_reply":"2024-11-01T17:57:59.192252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint_filepath = '/kaggle/working/checkpoint.model.keras'\n# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n#     filepath=checkpoint_filepath,\n#     monitor='val_color_accuracy',\n#     mode='max',\n#     save_best_only=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T17:58:02.761992Z","iopub.execute_input":"2024-11-01T17:58:02.762396Z","iopub.status.idle":"2024-11-01T17:58:02.766593Z","shell.execute_reply.started":"2024-11-01T17:58:02.762351Z","shell.execute_reply":"2024-11-01T17:58:02.765566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nclass MacroF1Score(tf.keras.metrics.Metric):\n    def __init__(self, name=\"macro_f1_score\", **kwargs):\n        super(MacroF1Score, self).__init__(name=name, **kwargs)\n        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Ensure consistency in data types\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(K.round(y_pred), tf.float32)\n\n        # Calculate true positives, false positives, and false negatives\n        self.tp.assign_add(K.sum(y_true * y_pred))\n        self.fp.assign_add(K.sum((1 - y_true) * y_pred))\n        self.fn.assign_add(K.sum(y_true * (1 - y_pred)))\n\n    def result(self):\n        precision = self.tp / (self.tp + self.fp + K.epsilon())\n        recall = self.tp / (self.tp + self.fn + K.epsilon())\n        f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n        return f1\n\n    def reset_states(self):\n        self.tp.assign(0)\n        self.fp.assign(0)\n        self.fn.assign(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:01:50.237504Z","iopub.execute_input":"2024-11-01T18:01:50.237878Z","iopub.status.idle":"2024-11-01T18:01:50.248972Z","shell.execute_reply.started":"2024-11-01T18:01:50.237843Z","shell.execute_reply":"2024-11-01T18:01:50.247826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AverageF1Callback(tf.keras.callbacks.Callback):\n    def __init__(self, patience=10, filepath='checkpoint.model.keras'):\n        super(AverageF1Callback, self).__init__()\n        self.patience = patience\n        self.best_avg_f1 = -1\n        self.wait = 0\n        self.filepath = filepath\n\n    def on_epoch_end(self, epoch, logs=None):\n        # Compute the average macro F1 score across all outputs\n        avg_f1 = np.mean([\n            logs.get(\"val_color_macro_f1_score\", 0),\n            logs.get(\"val_neck_macro_f1_score\", 0),\n            logs.get(\"val_pattern_macro_f1_score\", 0),\n            logs.get(\"val_print_macro_f1_score\", 0),\n            logs.get(\"val_sleeve_macro_f1_score\", 0)\n        ])\n\n        if avg_f1 > self.best_avg_f1:\n            self.best_avg_f1 = avg_f1\n            self.wait = 0\n            # Save best model\n            self.model.save(self.filepath)\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                print(f\"\\nEpoch {epoch}: early stopping\")\n                self.model.stop_training = True\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# def macro_f1_score(y_true, y_pred):\n#     y_pred = K.round(y_pred)  # Convert probabilities to binary labels (0 or 1)\n#     tp = K.sum(K.round(y_true * y_pred))  # True positives\n#     fp = K.sum(K.round((1 - y_true) * y_pred))  # False positives\n#     fn = K.sum(K.round(y_true * (1 - y_pred)))  # False negatives\n\n#     precision = tp / (tp + fp + K.epsilon())\n#     recall = tp / (tp + fn + K.epsilon())\n#     f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n#     return f1\n\n# Adjust the ModelCheckpoint to monitor the macro_f1_score across validation data\ncheckpoint_filepath = '/kaggle/working/checkpoint.model.keras'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_macro_f1_score',  # Use the custom F1 metric\n    mode='max',\n    save_best_only=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:01:52.726297Z","iopub.execute_input":"2024-11-01T18:01:52.727045Z","iopub.status.idle":"2024-11-01T18:01:52.732484Z","shell.execute_reply.started":"2024-11-01T18:01:52.727003Z","shell.execute_reply":"2024-11-01T18:01:52.731457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a model with five output heads for each attribute\ninputs = layers.Input(shape=IMAGE_SIZE)\nx = base_model(inputs, training=True)\nx = layers.GlobalAveragePooling2D()(x)\n\n# Define output layers for each attribute\noutput_color = layers.Dense(NUM_CLASSES_COLOR, activation='softmax', name='color')(x)\noutput_neck = layers.Dense(NUM_CLASSES_NECK, activation='softmax', name='neck')(x)\noutput_pattern = layers.Dense(NUM_CLASSES_PATTERN, activation='softmax', name='pattern')(x)\noutput_print = layers.Dense(NUM_CLASSES_PRINT, activation='softmax', name='print')(x)\noutput_sleeve = layers.Dense(NUM_CLASSES_SLEEVE, activation='softmax', name='sleeve')(x)\n\n# Define the model\nmodel = models.Model(inputs=inputs, outputs=[output_color, output_neck, output_pattern, output_print, output_sleeve])\n\n# Compile the model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=5*1e-5),\n    loss={\n        'color': 'categorical_crossentropy',\n        'neck': 'categorical_crossentropy',\n        'pattern': 'categorical_crossentropy',\n        'print': 'categorical_crossentropy',\n        'sleeve': 'categorical_crossentropy'\n    },\n    metrics={\n        'color': ['accuracy', MacroF1Score()],\n        'neck': ['accuracy', MacroF1Score()],\n        'pattern': ['accuracy', MacroF1Score()],\n        'print': ['accuracy', MacroF1Score()],\n        'sleeve': ['accuracy', MacroF1Score()]\n    }\n)\n# Summary of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-01T18:02:13.232071Z","iopub.execute_input":"2024-11-01T18:02:13.232879Z","iopub.status.idle":"2024-11-01T18:02:13.318427Z","shell.execute_reply.started":"2024-11-01T18:02:13.232838Z","shell.execute_reply":"2024-11-01T18:02:13.317532Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate the custom callback\naverage_f1_callback = AverageF1ScoreCallback(patience=10, filepath=checkpoint_filepath)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_avg_macro_f1_score',  # Using the custom F1 metric\n    patience=10,\n    mode='max',\n    restore_best_weights=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:02:16.481010Z","iopub.execute_input":"2024-11-01T18:02:16.481738Z","iopub.status.idle":"2024-11-01T18:02:16.486560Z","shell.execute_reply.started":"2024-11-01T18:02:16.481695Z","shell.execute_reply":"2024-11-01T18:02:16.485319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from keras.callbacks import ReduceLROnPlateau\n\n# # Add this callback to your training\n# reduce_lr = ReduceLROnPlateau(monitor='val_color_accuracy', factor=0.5, patience=3, min_lr=1e-7)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:02:16.961555Z","iopub.execute_input":"2024-11-01T18:02:16.962300Z","iopub.status.idle":"2024-11-01T18:02:16.966014Z","shell.execute_reply.started":"2024-11-01T18:02:16.962257Z","shell.execute_reply":"2024-11-01T18:02:16.965131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_avg_macro_f1_score',\n    factor=0.5,\n    patience=5,\n    min_lr=1e-7,\n    mode='max'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:02:21.661785Z","iopub.execute_input":"2024-11-01T18:02:21.662176Z","iopub.status.idle":"2024-11-01T18:02:21.667336Z","shell.execute_reply.started":"2024-11-01T18:02:21.662127Z","shell.execute_reply":"2024-11-01T18:02:21.666085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nhistory = model.fit(\n    train_generator,  # Image data\n    validation_data=(X_val, {\n        'color': val_color_labels,\n        'neck': val_neck_labels,\n        'pattern': val_pattern_labels,\n        'print': val_print_labels,\n        'sleeve': val_sleeve_labels\n    }),\n    epochs=100,\n    callbacks=[model_checkpoint_callback, early_stopping, reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T18:02:26.061617Z","iopub.execute_input":"2024-11-01T18:02:26.062018Z","iopub.status.idle":"2024-11-01T20:02:11.764142Z","shell.execute_reply.started":"2024-11-01T18:02:26.061978Z","shell.execute_reply":"2024-11-01T20:02:11.763109Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming 'history' is the output from model.fit()\n# Example: history = model.fit(...)\n\n# Plotting the accuracy\nplt.figure(figsize=(12, 6))\n\n# Plot training accuracy\nplt.plot(history.history['color_accuracy'], label='Color Train Accuracy', color='blue')\nplt.plot(history.history['neck_accuracy'], label='Neck Train Accuracy', color='orange')\nplt.plot(history.history['pattern_accuracy'], label='Pattern Train Accuracy', color='green')\nplt.plot(history.history['print_accuracy'], label='Print Train Accuracy', color='red')\nplt.plot(history.history['sleeve_accuracy'], label='Sleeve Train Accuracy', color='purple')\n\n# Plot validation accuracy\nplt.plot(history.history['val_color_accuracy'], label='Color Validation Accuracy', linestyle='dashed', color='blue')\nplt.plot(history.history['val_neck_accuracy'], label='Neck Validation Accuracy', linestyle='dashed', color='orange')\nplt.plot(history.history['val_pattern_accuracy'], label='Pattern Validation Accuracy', linestyle='dashed', color='green')\nplt.plot(history.history['val_print_accuracy'], label='Print Validation Accuracy', linestyle='dashed', color='red')\nplt.plot(history.history['val_sleeve_accuracy'], label='Sleeve Validation Accuracy', linestyle='dashed', color='purple')\n\n# Adding labels and title\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:06:50.450052Z","iopub.execute_input":"2024-11-01T20:06:50.450477Z","iopub.status.idle":"2024-11-01T20:06:50.899127Z","shell.execute_reply.started":"2024-11-01T20:06:50.450429Z","shell.execute_reply":"2024-11-01T20:06:50.898160Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T20:07:15.728643Z","iopub.execute_input":"2024-11-01T20:07:15.729525Z","iopub.status.idle":"2024-11-01T20:07:15.733370Z","shell.execute_reply.started":"2024-11-01T20:07:15.729480Z","shell.execute_reply":"2024-11-01T20:07:15.732344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T20:07:16.143155Z","iopub.execute_input":"2024-11-01T20:07:16.143500Z","iopub.status.idle":"2024-11-01T20:07:16.148189Z","shell.execute_reply.started":"2024-11-01T20:07:16.143466Z","shell.execute_reply":"2024-11-01T20:07:16.147131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T20:07:28.383026Z","iopub.execute_input":"2024-11-01T20:07:28.383728Z","iopub.status.idle":"2024-11-01T20:07:28.388562Z","shell.execute_reply.started":"2024-11-01T20:07:28.383686Z","shell.execute_reply":"2024-11-01T20:07:28.387465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FileLink(r'/kaggle/working/checkpoint.model.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T20:07:28.862867Z","iopub.execute_input":"2024-11-01T20:07:28.863204Z","iopub.status.idle":"2024-11-01T20:07:28.869315Z","shell.execute_reply.started":"2024-11-01T20:07:28.863169Z","shell.execute_reply":"2024-11-01T20:07:28.868396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}